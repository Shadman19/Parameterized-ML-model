{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMVaJ8gqTO7EFe0LLRSBezO",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Shadman19/Parameterized-ML-model/blob/main/Parameterized_Machine_Learning_Model_Training_with_PyTorch_Shadman.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 1. Introduction:\n",
        "Overview and Instructions\n",
        "The notebook will begin with a brief overview of the purpose, instructions on how to select datasets, models, and configure the training loop.\n",
        "\n",
        "\n",
        "# Machine Learning Model Training with PyTorch\n",
        "This notebook allows flexible, parameterized training of models using PyTorch. You can select datasets and models from the `torchvision` library, and configure training parameters like batch size, learning rate, and epochs.\n",
        "\n",
        "## Features:\n",
        "- Support for various datasets and models from `torchvision`.\n",
        "- Robust error handling with suggestions for typos.\n",
        "- Optional verbosity flag for detailed training output.\n",
        "- Early stopping based on validation loss.\n",
        "\n"
      ],
      "metadata": {
        "id": "1FEeeXYGC6JP"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 2. Setup: Import Libraries and Dependencies"
      ],
      "metadata": {
        "id": "OUlUOSmbDUYJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import DataLoader\n",
        "from torchvision import datasets, models, transforms\n",
        "from tqdm import tqdm\n",
        "import matplotlib.pyplot as plt\n",
        "import torch.nn.functional as F\n",
        "import numpy as np\n",
        "\n",
        "# For error handling and suggestions\n",
        "import difflib"
      ],
      "metadata": {
        "id": "A9mq7RH0C82p"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 3. Dataset Selection: Parameterized Dataset Loading with Error Handling\n",
        "We need to create a flexible loading mechanism for the dataset with error handling for typos."
      ],
      "metadata": {
        "id": "MCn-8fm_DcsS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Function to list all available datasets\n",
        "def list_available_datasets():\n",
        "    return [name for name in dir(datasets) if not name.startswith('__')]\n",
        "\n",
        "# Function to load dataset based on parameterized input\n",
        "def load_dataset(dataset_name, batch_size):\n",
        "    available_datasets = list_available_datasets()\n",
        "\n",
        "    if dataset_name not in available_datasets:\n",
        "        # Suggest closest matches for typos\n",
        "        suggestions = difflib.get_close_matches(dataset_name, available_datasets)\n",
        "        raise ValueError(f\"Dataset '{dataset_name}' not found. Did you mean: {suggestions}?\")\n",
        "\n",
        "    # Default transformations\n",
        "    transform = transforms.Compose([transforms.ToTensor(), transforms.Normalize((0.5,), (0.5,))])\n",
        "\n",
        "    # Dataset loading\n",
        "    dataset_class = getattr(datasets, dataset_name)\n",
        "\n",
        "    train_dataset = dataset_class(root='./data', train=True, download=True, transform=transform)\n",
        "    test_dataset = dataset_class(root='./data', train=False, download=True, transform=transform)\n",
        "\n",
        "    # DataLoader\n",
        "    train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
        "    test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)\n",
        "\n",
        "    return train_loader, test_loader\n"
      ],
      "metadata": {
        "id": "yhWFYy0oDZFa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 4. Model Selection: Parameterized Model Loading with Error Handling"
      ],
      "metadata": {
        "id": "RtMKbEO4DpGR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Function to list all available models\n",
        "def list_available_models():\n",
        "    return [name for name in dir(models) if callable(getattr(models, name)) and not name.startswith('__')]\n",
        "\n",
        "# Function to load model based on parameterized input\n",
        "def load_model(model_name, num_classes=10):\n",
        "    available_models = list_available_models()\n",
        "\n",
        "    if model_name not in available_models:\n",
        "        # Suggest closest matches for typos\n",
        "        suggestions = difflib.get_close_matches(model_name, available_models)\n",
        "        raise ValueError(f\"Model '{model_name}' not found. Did you mean: {suggestions}?\")\n",
        "\n",
        "    model_class = getattr(models, model_name)\n",
        "\n",
        "    # Load pre-trained model if available\n",
        "    model = model_class(pretrained=True)\n",
        "\n",
        "    # Adjust for number of classes (for CIFAR10, typically 10)\n",
        "    if model_name.startswith('resnet') or model_name.startswith('densenet'):\n",
        "        model.fc = nn.Linear(model.fc.in_features, num_classes)\n",
        "    elif model_name.startswith('vgg') or model_name.startswith('alexnet'):\n",
        "        model.classifier[-1] = nn.Linear(model.classifier[-1].in_features, num_classes)\n",
        "\n",
        "    return model\n"
      ],
      "metadata": {
        "id": "ygOGJsZxDn55"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 5. Training: Training Loop with Optional Early Stopping and Verbosity Control\n",
        "Hereâ€™s how to set up the training loop, including a verbosity flag and early stopping:"
      ],
      "metadata": {
        "id": "-VccxMIrDwnC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Training loop with optional verbosity and early stopping\n",
        "def train_model(model, train_loader, test_loader, epochs, learning_rate, patience=None, min_delta=0.01, verbosity=True):\n",
        "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "    model.to(device)\n",
        "\n",
        "    optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
        "    criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "    best_loss = np.Inf\n",
        "    no_improvement = 0\n",
        "\n",
        "    for epoch in range(epochs):\n",
        "        model.train()\n",
        "        running_loss = 0.0\n",
        "        correct, total = 0, 0\n",
        "\n",
        "        # Using tqdm for progress bar\n",
        "        pbar = tqdm(train_loader, desc=f'Epoch {epoch+1}/{epochs}', disable=not verbosity)\n",
        "\n",
        "        for inputs, labels in pbar:\n",
        "            inputs, labels = inputs.to(device), labels.to(device)\n",
        "            optimizer.zero_grad()\n",
        "            outputs = model(inputs)\n",
        "            loss = criterion(outputs, labels)\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "            running_loss += loss.item()\n",
        "            _, predicted = torch.max(outputs, 1)\n",
        "            correct += (predicted == labels).sum().item()\n",
        "            total += labels.size(0)\n",
        "\n",
        "        train_loss = running_loss / len(train_loader)\n",
        "        train_acc = correct / total\n",
        "\n",
        "        # Validation phase\n",
        "        val_loss, val_acc = evaluate_model(model, test_loader, criterion, device)\n",
        "\n",
        "        if verbosity:\n",
        "            print(f'Epoch {epoch+1}, Train Loss: {train_loss:.4f}, Train Acc: {train_acc:.4f}, Val Loss: {val_loss:.4f}, Val Acc: {val_acc:.4f}')\n",
        "\n",
        "        # Early stopping logic\n",
        "        if patience:\n",
        "            if val_loss < best_loss - min_delta:\n",
        "                best_loss = val_loss\n",
        "                no_improvement = 0\n",
        "            else:\n",
        "                no_improvement += 1\n",
        "                if no_improvement >= patience:\n",
        "                    print(f\"Early stopping at epoch {epoch+1}\")\n",
        "                    break\n",
        "\n",
        "# Function to evaluate model on test data\n",
        "def evaluate_model(model, test_loader, criterion, device):\n",
        "    model.eval()\n",
        "    running_loss = 0.0\n",
        "    correct, total = 0, 0\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for inputs, labels in test_loader:\n",
        "            inputs, labels = inputs.to(device), labels.to(device)\n",
        "            outputs = model(inputs)\n",
        "            loss = criterion(outputs, labels)\n",
        "\n",
        "            running_loss += loss.item()\n",
        "            _, predicted = torch.max(outputs, 1)\n",
        "            correct += (predicted == labels).sum().item()\n",
        "            total += labels.size(0)\n",
        "\n",
        "    test_loss = running_loss / len(test_loader)\n",
        "    test_acc = correct / total\n",
        "    return test_loss, test_acc\n"
      ],
      "metadata": {
        "id": "scZ1ahhPDuGw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 6. Evaluation: Summary of Results\n",
        "# Conclusion\n",
        "This notebook demonstrated a flexible way to train and evaluate models on various datasets using PyTorch. It incorporates robust error handling, early stopping, and customizable verbosity for the training process.\n"
      ],
      "metadata": {
        "id": "G8eLJVABD6HB"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "GhTXv5V0D2IB"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}